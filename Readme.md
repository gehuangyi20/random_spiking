
## Random Spiking and Systematic Evaluation of Defenses Against Adversarial Examples

The paper is accepted by Codaspy2020, and can be downloaded at
[https://arxiv.org/abs/1812.01804](https://arxiv.org/abs/1812.01804)

## Abstract

Image classifiers often suffer from adversarial examples, which are generated by strategically
adding a small amount of noise to input images to trick classifiers into misclassification. 
Over the years, many defense mechanisms have been proposed, and different researchers have 
made seemingly contradictory claims on their effectiveness. We present an analysis of 
possible adversarial models, and propose an evaluation framework for comparing different 
defense mechanisms. As part of the framework, we introduce a more powerful and realistic 
adversary strategy. Furthermore, we propose a new defense mechanism called Random Spiking (RS),
which generalizes dropout and introduces random noises in the training process in a controlled manner.
Evaluations under our proposed framework suggest RS delivers better protection against adversarial
examples than many existing schemes.

## Random spiking layer
The implementation of random spiking layer can be found in 
[RsNet/random_spiking/nn_ops.py](RsNet/random_spiking/nn_ops.py)

## Usage
Please see [INSTRUCTIONS.md](Instruction.md) for the usage.

## Software Requirements:
The code has been tested on GTX 1080Ti servers. Sample models are provided.

- Tensorflow-gpu (v1.13.1)
- Keras (v2.3.1)
- Numpy (v1.18)
- scipy (v1.1.0)
- easydict matplotlib Pillow

## License
This project is under the MIT license. See [LICENSE](LICENSE) for details.

## Citation 
```
@inproceedings{Ge_2020_codaspy,
    author = {Ge, Huangyi and Chau, Sze Yiu and Ribeiro, Bruno and Li, Ninghui},
    title = {Random Spiking and Systematic Evaluation of Defenses Against Adversarial Examples},
    year = {2020},
    isbn = {9781450371070},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3374664.3375736},
    doi = {10.1145/3374664.3375736},
    booktitle = {Proceedings of the Tenth ACM Conference on Data and Application Security and Privacy},
    pages = {85–96},
    numpages = {12},
    keywords = {random spiking, adversarial example, neural network},
    location = {New Orleans, LA, USA},
    series = {CODASPY ’20}
}
```
